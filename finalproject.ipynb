{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f6413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49771547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\programdata\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfced91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\programdata\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in d:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: torch==1.11.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ec9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aca1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config(object):\n",
    "    \"\"\"\n",
    "    定义一个配置类\n",
    "    \"\"\"\n",
    "    # adjust parameter\n",
    "    data_path = './data'\n",
    "    virs = 'result'\n",
    "    num_workers = 4  \n",
    "    img_size = 96  \n",
    "    batch_size = 256  \n",
    "    max_epoch = 400   \n",
    "    lr1 = 2e-4  # learn rate\n",
    "    lr2 = 2e-4  \n",
    "    beta1 = 0.5  # Adam\n",
    "    gpu = False \n",
    "    nz = 100  \n",
    "    ngf = 64  \n",
    "    ndf = 64  \n",
    "\n",
    "    \n",
    "    save_path = 'imgs3/'  \n",
    "    \n",
    "    d_every = 1  # \n",
    "    g_every = 5  # \n",
    "    save_every = 5  # \n",
    "    netd_path = None\n",
    "    netg_path = None\n",
    "\n",
    "    # result image\n",
    "    gen_img = \"result.png\"\n",
    "    \n",
    "    gen_num = 64\n",
    "    gen_search_num = 512\n",
    "    gen_mean = 0   \n",
    "    gen_std = 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dff595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Config()\n",
    "\n",
    "#generator\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NetG, self).__init__()\n",
    "        # self.ngf\n",
    "        self.ngf = opt.ngf\n",
    "        self.Gene = nn.Sequential(\n",
    "            # output = (input - 1)*stride + output_padding - 2*padding + kernel_size\n",
    "            nn.ConvTranspose2d(in_channels=opt.nz, out_channels=self.ngf * 8, kernel_size=4, stride=1, padding=0, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input4*4*ngf*8\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 8, out_channels=self.ngf * 4, kernel_size=4, stride=2, padding=1, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input8*8*ngf*4\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 4, out_channels=self.ngf * 2, kernel_size=4, stride=2, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input16*16*ngf*2\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 2, out_channels=self.ngf, kernel_size=4, stride=2, padding=1, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input32*32*ngf\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf, out_channels=3, kernel_size=5, stride=3, padding=1, bias =False),\n",
    "\n",
    "            nn.Tanh(),\n",
    "\n",
    "        )# output96*96*3\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Gene(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c15f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class NetD(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NetD, self).__init__()\n",
    "\n",
    "        self.ndf = opt.ndf\n",
    "        self.Discrim = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=3, out_channels= self.ndf, kernel_size= 5, stride= 3, padding= 1, bias=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace= True),\n",
    "\n",
    "            # input:(ndf, 32, 32)\n",
    "            nn.Conv2d(in_channels= self.ndf, out_channels= self.ndf * 2, kernel_size= 4, stride= 2, padding= 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *2, 16, 16)\n",
    "            nn.Conv2d(in_channels= self.ndf * 2, out_channels= self.ndf *4, kernel_size= 4, stride= 2, padding= 1,bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *4, 8, 8)\n",
    "            nn.Conv2d(in_channels= self.ndf *4, out_channels= self.ndf *8, kernel_size= 4, stride= 2, padding= 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf *8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *8, 4, 4)\n",
    "            # output:(1, 1, 1)\n",
    "            nn.Conv2d(in_channels= self.ndf *8, out_channels= 1, kernel_size= 4, stride= 1, padding= 0, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Discrim(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58060dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "\n",
    "\n",
    "    for k_, v_ in kwargs.items():\n",
    "        setattr(opt, k_, v_)\n",
    "\n",
    "    if opt.gpu:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    \n",
    "    transforms = tv.transforms.Compose([\n",
    "        # 3*96*96\n",
    "        tv.transforms.Resize(opt.img_size),   \n",
    "        \n",
    "        tv.transforms.CenterCrop(opt.img_size),\n",
    "\n",
    "        \n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    dataset = tv.datasets.ImageFolder(root=opt.data_path, transform=transforms)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,      \n",
    "        batch_size=opt.batch_size,    \n",
    "        shuffle=True,     \n",
    "        \n",
    "        drop_last=True           \n",
    "    )\n",
    "\n",
    "    \n",
    "    netg, netd = NetG(opt), NetD(opt)\n",
    "   \n",
    "    map_location = lambda storage, loc: storage\n",
    "\n",
    "\n",
    "    \n",
    "    if opt.netg_path:\n",
    "        netg.load_state_dict(torch.load(f=opt.netg_path, map_location=map_location))\n",
    "    if opt.netd_path:\n",
    "        netd.load_state_dict(torch.load(f=opt.netd_path, map_location=map_location))\n",
    "\n",
    "    \n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    \n",
    "    optimize_g = torch.optim.Adam(netg.parameters(), lr=opt.lr1, betas=(opt.beta1, 0.999))\n",
    "    optimize_d = torch.optim.Adam(netd.parameters(), lr=opt.lr2, betas=(opt.beta1, 0.999))\n",
    "\n",
    "   \n",
    "    criterions = nn.BCELoss().to(device)\n",
    "\n",
    "    \n",
    "    true_labels = torch.ones(opt.batch_size).to(device)\n",
    "    fake_labels = torch.zeros(opt.batch_size).to(device)\n",
    "\n",
    "    \n",
    "    noises = torch.randn(opt.batch_size, opt.nz, 1, 1).to(device)\n",
    "\n",
    "    \n",
    "    fix_noises = torch.randn(opt.batch_size, opt.nz, 1, 1).to(device)\n",
    "\n",
    "    \n",
    "    for epoch in range(opt.max_epoch):\n",
    "        \n",
    "        for ii_, (img, _) in tqdm((enumerate(dataloader))):\n",
    "            \n",
    "            real_img = img.to(device)\n",
    "\n",
    "           \n",
    "            if ii_ % opt.d_every == 0:\n",
    "               \n",
    "                optimize_d.zero_grad()\n",
    "\n",
    "               \n",
    "                output = netd(real_img)\n",
    "                error_d_real = criterions(output, true_labels)\n",
    "                error_d_real.backward()\n",
    "                noises = noises.detach()\n",
    "                fake_image = netg(noises).detach()\n",
    "                output = netd(fake_image)\n",
    "                error_d_fake = criterions(output, fake_labels)\n",
    "                error_d_fake.backward()\n",
    "                optimize_d.step()\n",
    "\n",
    "            # train Discriminator\n",
    "            if ii_ % opt.g_every == 0:\n",
    "                optimize_g.zero_grad()\n",
    "                noises.data.copy_(torch.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_image = netg(noises)\n",
    "                output = netd(fake_image)\n",
    "                error_g = criterions(output, true_labels)\n",
    "                error_g.backward()\n",
    "                optimize_g.step()\n",
    "\n",
    "        # save model\n",
    "        if (epoch + 1) % opt.save_every == 0:\n",
    "            fix_fake_image = netg(fix_noises)\n",
    "            tv.utils.save_image(fix_fake_image.data[:64], \"%s/%s.png\" % (opt.save_path, epoch), normalize=True)\n",
    "\n",
    "            torch.save(netd.state_dict(),  'imgs2/' + 'netd_{0}.pth'.format(epoch))\n",
    "            torch.save(netg.state_dict(),  'imgs2/' + 'netg_{0}.pth'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f202a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:56,  7.99s/it]"
     ]
    }
   ],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.no_grad()\n",
    "def generate(**kwargs):\n",
    "    # to generate pics\n",
    "\n",
    "    for k_, v_ in kwargs.items():\n",
    "        setattr(opt, k_, v_)\n",
    "\n",
    "    device = torch.device(\"cuda\") if opt.gpu else torch.device(\"cpu\")\n",
    "\n",
    "    # upload weight\n",
    "    netg, netd = NetG(opt).eval(), NetD(opt).eval()\n",
    "    map_location = lambda storage, loc: storage\n",
    "\n",
    "    # opt.netd_path\n",
    "    netd.load_state_dict(torch.load('imgs2/netd_399.pth', map_location=map_location), False)\n",
    "    netg.load_state_dict(torch.load('imgs2/netg_399.pth', map_location=map_location), False)\n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    # generate trained pics\n",
    "    noise = torch.randn(opt.gen_search_num, opt.nz, 1, 1).normal_(opt.gen_mean, opt.gen_std).to(device)\n",
    "\n",
    "    fake_image = netg(noise)\n",
    "    score = netd(fake_image).detach()\n",
    "\n",
    "    indexs = score.topk(opt.gen_num)[1]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ii in indexs:\n",
    "        result.append(fake_image.data[ii])\n",
    "\n",
    "    # opt.gen_img\n",
    "    tv.utils.save_image(torch.stack(result), opt.gen_img, normalize=True, range=(-1, 1))\n",
    "\n",
    "def main():\n",
    "    train()\n",
    "    generate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7291990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be59047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
