{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b399fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [02:29,  7.89s/it]\n",
      "19it [02:14,  7.09s/it]\n",
      "19it [02:15,  7.11s/it]\n",
      "19it [02:18,  7.29s/it]\n",
      "19it [02:07,  6.70s/it]\n",
      "19it [01:55,  6.10s/it]\n",
      "19it [01:56,  6.11s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [18:42, 59.05s/it] \n",
      "19it [02:00,  6.32s/it]\n",
      "19it [02:03,  6.47s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:53,  6.00s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:55,  6.07s/it]\n",
      "19it [01:55,  6.06s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:54,  6.01s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:51,  5.89s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:55,  6.07s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:57,  6.17s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:55,  6.06s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:54,  6.05s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:54,  6.01s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  6.00s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:54,  6.05s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:51,  5.89s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:54,  6.04s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:54,  6.03s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:54,  6.03s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:54,  6.03s/it]\n",
      "19it [01:53,  6.00s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:54,  6.02s/it]\n",
      "19it [01:54,  6.02s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:54,  6.01s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:55,  6.08s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:55,  6.08s/it]\n",
      "19it [02:04,  6.53s/it]\n",
      "19it [01:53,  5.95s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:54,  6.02s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:54,  6.04s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.92s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:56,  6.11s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.95s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:53,  5.96s/it]\n",
      "19it [01:52,  5.93s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [01:57,  6.17s/it]\n",
      "19it [02:02,  6.47s/it]\n",
      "19it [02:03,  6.52s/it]\n",
      "19it [02:00,  6.33s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [02:20,  7.40s/it]\n",
      "19it [01:56,  6.14s/it]\n",
      "19it [01:56,  6.12s/it]\n",
      "19it [01:53,  5.97s/it]\n",
      "19it [01:51,  5.88s/it]\n",
      "19it [01:50,  5.83s/it]\n",
      "19it [01:50,  5.82s/it]\n",
      "19it [01:51,  5.85s/it]\n",
      "19it [01:51,  5.86s/it]\n",
      "19it [01:55,  6.07s/it]\n",
      "19it [01:55,  6.10s/it]\n",
      "19it [01:56,  6.13s/it]\n",
      "19it [01:55,  6.10s/it]\n",
      "19it [01:55,  6.06s/it]\n",
      "19it [01:55,  6.08s/it]\n",
      "19it [01:51,  5.86s/it]\n",
      "19it [01:53,  5.99s/it]\n",
      "19it [01:51,  5.88s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [01:50,  5.83s/it]\n",
      "19it [01:51,  5.85s/it]\n",
      "19it [01:50,  5.83s/it]\n",
      "19it [01:53,  5.98s/it]\n",
      "19it [01:51,  5.86s/it]\n",
      "19it [01:51,  5.85s/it]\n",
      "19it [01:51,  5.86s/it]\n",
      "19it [01:50,  5.83s/it]\n",
      "19it [01:50,  5.82s/it]\n",
      "19it [01:52,  5.90s/it]\n",
      "19it [01:51,  5.86s/it]\n",
      "19it [01:50,  5.84s/it]\n",
      "19it [01:51,  5.84s/it]\n",
      "19it [01:59,  6.30s/it]\n",
      "19it [01:52,  5.94s/it]\n",
      "19it [02:01,  6.40s/it]\n",
      "19it [02:01,  6.42s/it]\n",
      "19it [02:00,  6.32s/it]\n",
      "19it [02:26,  7.73s/it]\n",
      "19it [02:39,  8.42s/it]\n",
      "19it [02:20,  7.37s/it]\n",
      "19it [02:27,  7.78s/it]\n",
      "19it [02:43,  8.59s/it]\n",
      "19it [02:45,  8.70s/it]\n",
      "19it [02:19,  7.33s/it]\n",
      "19it [01:52,  5.91s/it]\n",
      "19it [02:12,  6.97s/it]\n",
      "19it [01:59,  6.29s/it]\n",
      "19it [02:25,  7.67s/it]\n",
      "19it [02:26,  7.73s/it]\n",
      "19it [02:21,  7.43s/it]\n",
      "19it [02:28,  7.81s/it]\n",
      "19it [02:25,  7.66s/it]\n",
      "19it [02:18,  7.31s/it]\n",
      "19it [02:29,  7.87s/it]\n",
      "19it [02:35,  8.17s/it]\n",
      "19it [02:38,  8.33s/it]\n",
      "19it [02:38,  8.33s/it]\n",
      "19it [02:35,  8.19s/it]\n",
      "19it [02:42,  8.53s/it]\n",
      "19it [02:31,  7.97s/it]\n",
      "19it [02:32,  8.00s/it]\n",
      "19it [02:39,  8.40s/it]\n",
      "19it [02:33,  8.09s/it]\n",
      "19it [02:41,  8.50s/it]\n",
      "19it [02:45,  8.69s/it]\n",
      "19it [02:33,  8.09s/it]\n",
      "18it [02:31,  8.16s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# config\n",
    "class Config(object):\n",
    "    \"\"\"\n",
    "    定义一个配置类\n",
    "    \"\"\"\n",
    "    # adjust parameter\n",
    "    data_path = './data'\n",
    "    virs = 'result'\n",
    "    num_workers = 4  \n",
    "    img_size = 96  \n",
    "    batch_size = 256  \n",
    "    max_epoch = 400   \n",
    "    lr1 = 2e-4  # learn rate\n",
    "    lr2 = 2e-4  \n",
    "    beta1 = 0.5  # Adam\n",
    "    gpu = False \n",
    "    nz = 100  \n",
    "    ngf = 64  \n",
    "    ndf = 64  \n",
    "\n",
    "    \n",
    "    save_path = 'imgs/'  \n",
    "    \n",
    "    d_every = 1  # \n",
    "    g_every = 5  # \n",
    "    save_every = 5  # \n",
    "    netd_path = None\n",
    "    netg_path = None\n",
    "\n",
    "    # result image\n",
    "    gen_img = \"result.png\"\n",
    "    \n",
    "    gen_num = 64\n",
    "    gen_search_num = 512\n",
    "    gen_mean = 0   \n",
    "    gen_std = 1     \n",
    "\n",
    "\n",
    "opt = Config()\n",
    "\n",
    "#generator\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NetG, self).__init__()\n",
    "        # self.ngf\n",
    "        self.ngf = opt.ngf\n",
    "        self.Gene = nn.Sequential(\n",
    "            # output = (input - 1)*stride + output_padding - 2*padding + kernel_size\n",
    "            nn.ConvTranspose2d(in_channels=opt.nz, out_channels=self.ngf * 8, kernel_size=4, stride=1, padding=0, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input4*4*ngf*8\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 8, out_channels=self.ngf * 4, kernel_size=4, stride=2, padding=1, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input8*8*ngf*4\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 4, out_channels=self.ngf * 2, kernel_size=4, stride=2, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input16*16*ngf*2\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf * 2, out_channels=self.ngf, kernel_size=4, stride=2, padding=1, bias =False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # input32*32*ngf\n",
    "            nn.ConvTranspose2d(in_channels=self.ngf, out_channels=3, kernel_size=5, stride=3, padding=1, bias =False),\n",
    "\n",
    "            nn.Tanh(),\n",
    "\n",
    "        )# output96*96*3\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Gene(x)\n",
    "\n",
    "# Discriminator\n",
    "class NetD(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NetD, self).__init__()\n",
    "\n",
    "        self.ndf = opt.ndf\n",
    "        self.Discrim = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=3, out_channels= self.ndf, kernel_size= 5, stride= 3, padding= 1, bias=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace= True),\n",
    "\n",
    "            # input:(ndf, 32, 32)\n",
    "            nn.Conv2d(in_channels= self.ndf, out_channels= self.ndf * 2, kernel_size= 4, stride= 2, padding= 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *2, 16, 16)\n",
    "            nn.Conv2d(in_channels= self.ndf * 2, out_channels= self.ndf *4, kernel_size= 4, stride= 2, padding= 1,bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *4, 8, 8)\n",
    "            nn.Conv2d(in_channels= self.ndf *4, out_channels= self.ndf *8, kernel_size= 4, stride= 2, padding= 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf *8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            # input:(ndf *8, 4, 4)\n",
    "            # output:(1, 1, 1)\n",
    "            nn.Conv2d(in_channels= self.ndf *8, out_channels= 1, kernel_size= 4, stride= 1, padding= 0, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Discrim(x).view(-1)\n",
    "\n",
    "\n",
    "def train(**kwargs):\n",
    "\n",
    "\n",
    "    for k_, v_ in kwargs.items():\n",
    "        setattr(opt, k_, v_)\n",
    "\n",
    "    if opt.gpu:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    \n",
    "    transforms = tv.transforms.Compose([\n",
    "        # 3*96*96\n",
    "        tv.transforms.Resize(opt.img_size),   \n",
    "        \n",
    "        tv.transforms.CenterCrop(opt.img_size),\n",
    "\n",
    "        \n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    dataset = tv.datasets.ImageFolder(root=opt.data_path, transform=transforms)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,      \n",
    "        batch_size=opt.batch_size,    \n",
    "        shuffle=True,     \n",
    "        \n",
    "        drop_last=True           \n",
    "    )\n",
    "\n",
    "    \n",
    "    netg, netd = NetG(opt), NetD(opt)\n",
    "   \n",
    "    map_location = lambda storage, loc: storage\n",
    "\n",
    "\n",
    "    \n",
    "    if opt.netg_path:\n",
    "        netg.load_state_dict(torch.load(f=opt.netg_path, map_location=map_location))\n",
    "    if opt.netd_path:\n",
    "        netd.load_state_dict(torch.load(f=opt.netd_path, map_location=map_location))\n",
    "\n",
    "    \n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    \n",
    "    optimize_g = torch.optim.Adam(netg.parameters(), lr=opt.lr1, betas=(opt.beta1, 0.999))\n",
    "    optimize_d = torch.optim.Adam(netd.parameters(), lr=opt.lr2, betas=(opt.beta1, 0.999))\n",
    "\n",
    "   \n",
    "    criterions = nn.BCELoss().to(device)\n",
    "\n",
    "    \n",
    "    true_labels = torch.ones(opt.batch_size).to(device)\n",
    "    fake_labels = torch.zeros(opt.batch_size).to(device)\n",
    "\n",
    "    \n",
    "    noises = torch.randn(opt.batch_size, opt.nz, 1, 1).to(device)\n",
    "\n",
    "    \n",
    "    fix_noises = torch.randn(opt.batch_size, opt.nz, 1, 1).to(device)\n",
    "\n",
    "    \n",
    "    for epoch in range(opt.max_epoch):\n",
    "        \n",
    "        for ii_, (img, _) in tqdm((enumerate(dataloader))):\n",
    "            \n",
    "            real_img = img.to(device)\n",
    "\n",
    "           \n",
    "            if ii_ % opt.d_every == 0:\n",
    "               \n",
    "                optimize_d.zero_grad()\n",
    "\n",
    "               \n",
    "                output = netd(real_img)\n",
    "                error_d_real = criterions(output, true_labels)\n",
    "                error_d_real.backward()\n",
    "                noises = noises.detach()\n",
    "                fake_image = netg(noises).detach()\n",
    "                output = netd(fake_image)\n",
    "                error_d_fake = criterions(output, fake_labels)\n",
    "                error_d_fake.backward()\n",
    "                optimize_d.step()\n",
    "\n",
    "            # train Discriminator\n",
    "            if ii_ % opt.g_every == 0:\n",
    "                optimize_g.zero_grad()\n",
    "                noises.data.copy_(torch.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_image = netg(noises)\n",
    "                output = netd(fake_image)\n",
    "                error_g = criterions(output, true_labels)\n",
    "                error_g.backward()\n",
    "                optimize_g.step()\n",
    "\n",
    "        # save model\n",
    "        if (epoch + 1) % opt.save_every == 0:\n",
    "            fix_fake_image = netg(fix_noises)\n",
    "            tv.utils.save_image(fix_fake_image.data[:64], \"%s/%s.png\" % (opt.save_path, epoch), normalize=True)\n",
    "\n",
    "            torch.save(netd.state_dict(),  'imgs2/' + 'netd_{0}.pth'.format(epoch))\n",
    "            torch.save(netg.state_dict(),  'imgs2/' + 'netg_{0}.pth'.format(epoch))\n",
    "\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "@torch.no_grad()\n",
    "def generate(**kwargs):\n",
    "    # to generate pics\n",
    "\n",
    "    for k_, v_ in kwargs.items():\n",
    "        setattr(opt, k_, v_)\n",
    "\n",
    "    device = torch.device(\"cuda\") if opt.gpu else torch.device(\"cpu\")\n",
    "\n",
    "    # upload weight\n",
    "    netg, netd = NetG(opt).eval(), NetD(opt).eval()\n",
    "    map_location = lambda storage, loc: storage\n",
    "\n",
    "    # opt.netd_path\n",
    "    netd.load_state_dict(torch.load('imgs2/netd_399.pth', map_location=map_location), False)\n",
    "    netg.load_state_dict(torch.load('imgs2/netg_399.pth', map_location=map_location), False)\n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    # generate trained pics\n",
    "    noise = torch.randn(opt.gen_search_num, opt.nz, 1, 1).normal_(opt.gen_mean, opt.gen_std).to(device)\n",
    "\n",
    "    fake_image = netg(noise)\n",
    "    score = netd(fake_image).detach()\n",
    "\n",
    "    indexs = score.topk(opt.gen_num)[1]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ii in indexs:\n",
    "        result.append(fake_image.data[ii])\n",
    "\n",
    "    # opt.gen_img\n",
    "    tv.utils.save_image(torch.stack(result), opt.gen_img, normalize=True, range=(-1, 1))\n",
    "\n",
    "def main():\n",
    "    train()\n",
    "    generate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f1666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
